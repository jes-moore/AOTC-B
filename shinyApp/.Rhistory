dyLegend(show = "always",width = 600)
plot
plot <- dygraph(data[,c('Close','Volume')],
main = "", ylab = "Lots") %>%
dySeries("Close",strokeWidth = 2, label = "Longs",color = "#57B8FF") %>%
dySeries("Volume",axis = 'y2',label = "Net Position",color = "#2b2b2b",fillGraph = TRUE,strokeWidth = 0) %>%
#dySeries("Last",label = "Front Month WTI",strokeWidth = 2,strokePattern = "dashed",color = "#C67336",axis = 'y2') %>%
dyRangeSelector(height = 30,dateWindow = c(range(index(data))[2] - 180,range(index(data))[2])) %>%
dyAxis("x",drawGrid = FALSE) %>%
#dyAxis("y2", label = "Crude Price", independentTicks = FALSE) %>%
dyCrosshair(direction = "vertical") %>%
dyCSS("css/COTC.css") %>%
dyLegend(show = "always",width = 600)
plot
runApp()
plot <- dygraph(data[,c('Close','Volume')],
main = "", ylab = "Lots") %>%
dySeries("Close",strokeWidth = 2, label = "Price",color = "#57B8FF") %>%
dySeries("Volume",axis = ,label = "Volume",color = "#2b2b2b",fillGraph = TRUE,strokeWidth = 0) %>%
#dySeries("Last",label = "Front Month WTI",strokeWidth = 2,strokePattern = "dashed",color = "#C67336",axis = 'y2') %>%
dyRangeSelector(height = 30,dateWindow = c(range(index(data))[2] - 180,range(index(data))[2])) %>%
dyAxis("x",drawGrid = FALSE) %>%
#dyAxis("y2", label = "Crude Price", independentTicks = FALSE) %>%
dyAxis("y",drawGrid = FALSE,
valueFormatter = 'function(d){return d.toString().replace(/\\B(?=(\\d{3})+(?!\\d))/g, ",");}',
axisLabelFormatter = 'function(d){return d.toString().replace(/\\B(?=(\\d{3})+(?!\\d))/g, ",");}') %>%
dyCrosshair(direction = "vertical") %>%
dyCSS("css/sp2.css") %>%
dyLegend(show = "always",width = 600)
plot
plot <- dygraph(data[,c('Close','Volume')],
main = "", ylab = "Lots") %>%
dySeries("Close",strokeWidth = 2, label = "Price",color = "#57B8FF") %>%
dySeries("Volume",axis = 'y2' ,label = "Volume",color = "#2b2b2b",fillGraph = TRUE,strokeWidth = 0) %>%
dyRangeSelector(height = 30,dateWindow = c(range(index(data))[2] - 180,range(index(data))[2])) %>%
dyAxis("x",drawGrid = FALSE) %>%
#dyAxis("y2", label = "Crude Price", independentTicks = FALSE) %>%
dyAxis("y",drawGrid = FALSE,
valueFormatter = 'function(d){return d.toString().replace(/\\B(?=(\\d{3})+(?!\\d))/g, ",");}',
axisLabelFormatter = 'function(d){return d.toString().replace(/\\B(?=(\\d{3})+(?!\\d))/g, ",");}') %>%
dyCrosshair(direction = "vertical") %>%
dyCSS("css/sp2.css") %>%
dyLegend(show = "always",width = 600)
plot
plot
source('sharePricePlot2.R')
data <- cutdata()
data <- cutdata()
runApp()
runApp()
runApp()
runApp()
?fluidRow
?column
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?tq_get
ticker = 'FB'
getStats <- function(ticker){
tq_get(ticker,get='key.stats',from='2014-01-01')
}
getStats
?XBRL
??XBRL
?tq_get
?quantmod
?quantmod::getFinancials
?XBRL
??XBRL
?tq_get
library(XBRL)
??XBRL
install.packages('finreport')
install.packages('finreportr')
CompanyInfo("GOOG")
library(finreportr)
CompanyInfo("GOOG")
AnnualReports("FB")
GetIncome("TSLA", 2015)
GetIncome("FB", 2015)
FB
AnnualReports("FB")
?GetIncome
GetIncome("FB", 2016)
library(finreportr)
library(XBRL)
library(edgar)
library(data.table)
cik <- read.csv('data/cik_ticker.csv')
ticker = 'fb'
ticker <- toupper(ticker)
thisCIK <- cik$CIK[cik$Ticker == ticker]
filings <- fread('data/master_index.csv',stringsAsFactors = FALSE)
filings <- filings[filings$CIK == thisCIK,]
filings$INST <- paste('https://www.sec.gov/Archives/',
gsub('.txt','',gsub('-','',thisFilings$EDGAR_LINK)),
'/',tolower(ticker),'-',
gsub('-','',thisFilings$DATE_FILED),
'.xml',sep = '')
library(finreportr)
library(XBRL)
library(edgar)
library(rvest)
library(htmltidy)
library(httr)
library(dplyr)
cik <- read.csv('data/cik_ticker.csv')
object1 <- load("Master Index/2013master.Rda")
obj <- year.master
rm(object1)
object2 <- load("Master Index/2014master.Rda")
obj <- rbind(obj,year.master)
rm(object2)
object3 <- load("Master Index/2015master.Rda")
obj <- rbind(obj,year.master)
rm(object3)
object4 <- load("Master Index/2016master.Rda")
rm(object4)
obj <- rbind(obj,year.master)
object5 <- load("Master Index/2017master.Rda")
rm(object5)
obj <- rbind(obj,year.master)
rm(year.master)
obj <- obj[obj$CIK %in% cik$CIK,]
obj <- obj[obj$FORM_TYPE %in% c('10-Q','10-K'),]
obj <- merge(obj,cik[,2:3],by='CIK')
obj$EDGAR_LINK <- paste('https://www.sec.gov/Archives/',obj$EDGAR_LINK,sep='')
head(obj)
gsub('-','',tstrsplit(x = obj$EDGAR_LINK,'/')[8])
gsub('-','',tstrsplit(x = obj$EDGAR_LINK,'/')[8])[1]
?tstrsplit
tstrsplit(x = obj$EDGAR_LINK,'/')[[8]])
tstrsplit(x = obj$EDGAR_LINK,'/')[[8]]
gsub('-','',tstrsplit(x = obj$EDGAR_LINK,'/')[[8]])
tstrsplit(x = obj$EDGAR_LINK,'/')[[8]]
gsub('.txt','',gsub('-','',tstrsplit(x = obj$EDGAR_LINK,'/')[[8]]))
gsub('.txt','',tstrsplit(x = obj$EDGAR_LINK,'/')[8])
obj$html <- paste('https://www.sec.gov/Archives/edgar/data/',obj$CIK,
'/',
gsub('.txt','',gsub('-','',tstrsplit(x = obj$EDGAR_LINK,'/')[[8]])),
'/',
gsub('.txt','',tstrsplit(x = obj$EDGAR_LINK,'/')[[8]]),
'-index.htm',sep='')
obj
obj$html[479]
obj$html[480]
ReportPeriod <- function(url) {
# url <- paste0("https://www.sec.gov/Archives/edgar/data/", CIK, "/",
#               accession.no, "/", accession.no.raw, "-index.htm")
search.result <- xml2::read_html(url)
##   Generic function to extract info
ExtractInfo <- function(html.node) {
info <-
search.result %>%
rvest::html_nodes(html.node) %>%
rvest::html_text()
return(info)
}
report.period <- ExtractInfo(".formGrouping+ .formGrouping .info:nth-child(2)")
return(report.period)
}
obj$reportPeriod <- 0
library(doParallel)
cl <- makeCluster(6)
registerDoParallel(cl)
reportPeriod <- data.frame(reportPeriod = character)
reportPeriod = foreach(i=1:500,.export = c('ReportPeriod'),.packages='dplyr'  ,.combine='rbind') %dopar% {
data.frame(reportPeriod = ReportPeriod(obj$html[i]))
}
stopCluster(cl)
View(reportPeriod)
reportPeriod <- data.frame(reportPeriod = character)
reportPeriod = foreach(i=1:nrow(obj),.export = c('ReportPeriod'),.packages='dplyr'  ,.combine='rbind') %dopar% {
data.frame(reportPeriod = ReportPeriod(obj$html[i]))
}
stopCluster(cl)
stopCluster(cl)
library(doParallel)
cl <- makeCluster(6)
registerDoParallel(cl)
reportPeriod <- data.frame(reportPeriod = character)
reportPeriod = foreach(i=1:nrow(obj),.export = c('ReportPeriod'),.packages='dplyr'  ,.combine='rbind') %dopar% {
data.frame(reportPeriod = ReportPeriod(obj$html[i]))
}
stopCluster(cl)
obj$reportPeriod <- reportPeriod$reportPeriod
View(obj)
write.csv(obj,'data/tempEdgar.csv',row.names = FALSE)
obj[1]
obj[1,]
obj$EDGAR_LINK[1]
obj$reportPeriod[2]
obj$INST <- paste('https://www.sec.gov/Archives/edgar/data',
obj$CIK,'/',
gsub('.txt','',gsub('-','',tstrsplit(x = obj$EDGAR_LINK,'/')[[8]])),'/',
obj$Ticker,'-',
gsub('-','',obj$reportPeriod),'.xml')
library(finreportr)
library(XBRL)
library(edgar)
library(rvest)
library(htmltidy)
library(httr)
library(dplyr)
library(data.table)
obj$INST <- paste('https://www.sec.gov/Archives/edgar/data',
obj$CIK,'/',
gsub('.txt','',gsub('-','',tstrsplit(x = obj$EDGAR_LINK,'/')[[8]])),'/',
obj$Ticker,'-',
gsub('-','',obj$reportPeriod),'.xml')
obj$INST[1]
obj$INST <- paste('https://www.sec.gov/Archives/edgar/data',
obj$CIK,'/',
gsub('.txt','',gsub('-','',tstrsplit(x = obj$EDGAR_LINK,'/')[[8]])),'/',
obj$Ticker,'-',
gsub('-','',obj$reportPeriod),'.xml',sep='')
obj$INST[1]
obj$INST <- paste('https://www.sec.gov/Archives/edgar/data/',
obj$CIK,'/',
gsub('.txt','',gsub('-','',tstrsplit(x = obj$EDGAR_LINK,'/')[[8]])),'/',
obj$Ticker,'-',
gsub('-','',obj$reportPeriod),'.xml',sep='')
obj$INST[1]
"https://www.sec.gov/Archives/edgar/data/320193/000119312514383437/aapl-20140927.xml"
obj$INST <- paste('https://www.sec.gov/Archives/edgar/data/',
obj$CIK,'/',
gsub('.txt','',gsub('-','',tstrsplit(x = obj$EDGAR_LINK,'/')[[8]])),'/',
tolower(obj$Ticker),'-',
gsub('-','',obj$reportPeriod),'.xml',sep='')
obj$INST[1]
obj$INST[480]
write.csv(obj,'data/tempEdgar.csv',row.names = FALSE)
?XBRL
?xbrlDoAll
GetInstFile <- function(url) {
XBRL::xbrlDoAll(url, cache.dir=NULL, prefix.out ="out", verbose=FALSE)
}
file.remove("out_calculations.csv", "out_contexts.csv", "out_definitions.csv",
"out_elements.csv", "out_facts.csv", "out_footnotes.csv",
"out_labels.csv", "out_presentations.csv", "out_roles.csv", "out_units.csv")
unlink("XBRLcache", recursive = TRUE)
GetInstFile <- function(url) {
XBRL::xbrlDoAll(url, cache.dir=NULL, prefix.out ="out", verbose=FALSE)
}
GetInstFile <- function(url) {
XBRL::xbrlDoAll(url, cache.dir=NULL, prefix.out ="out", verbose=FALSE)
}
edgarFiles <- fread('data/tempEdgar.csv')
View(edgarFiles)
rm(list=ls())
ticker <- 'fb'
edgarFiles <- fread('data/tempEdgar.csv')
GetInstFile <- function(url) {
XBRL::xbrlDoAll(url, cache.dir=NULL, prefix.out ="out", verbose=FALSE)
}
description <- NULL
roleId <- NULL
labelRole <- NULL
labelString <- NULL
unitId <- NULL
fact <- NULL
contextId <- NULL
startDate <- NULL
ticker=edgarFiles$reportPeriod
ticker = 'fb'
edgarFiles$reportPeriod[1]
urls <- edgarFiles$INST[edgarFiles$Ticker == ticker &
edgarFiles$FORM_TYPE == '10-K' &
edgarFiles$reportPeriod > '2013-01-01']
urls
edgarFiles$DATE_FILED <- as.Date(edgarFiles$DATE_FILED)
head(edgarFiles)
urls <- edgarFiles$INST[edgarFiles$Ticker == ticker &
edgarFiles$FORM_TYPE == '10-K' &
edgarFiles$reportPeriod > as.Date('2013-01-01')]
urls
urls <- edgarFiles$INST[edgarFiles$Ticker == toupper(ticker) &
edgarFiles$FORM_TYPE == '10-K' &
edgarFiles$reportPeriod > as.Date('2013-01-01')]
urls
instanceFiles <- lapply(urls,GetInstFile(x))
instanceFiles <- lapply(urls,GetInstFile())
instanceFiles <- lapply(urls,GetInstFile
)
GetInstFile <- function(url) {
XBRL::xbrlDoAll(url, cache.dir=NULL, prefix.out ="out", verbose=FALSE)
}
GetInstFile <- function(url) {
XBRL::xbrlDoAll(url, cache.dir=NULL, prefix.out ="out", verbose=FALSE)
}
instanceFiles <- lapply(urls,GetInstFile)
url
urls
instanceFiles <- lapply(urls,GetInstFile)
GetInstFile(urls[1])
urls[1]
urls[[1]]
XBRL::xbrlDoAll(urls[1], cache.dir=NULL, prefix.out ="out", verbose=FALSE)
XBRL::xbrlDoAll(urls[2], cache.dir=NULL, prefix.out ="out", verbose=FALSE)
XBRL::xbrlDoAll(urls[3], cache.dir=NULL, prefix.out ="out", verbose=FALSE)
xbrlDoAll(urls[1])
xbrlDoAll(urls[1], cache.dir="NULL", prefix.out ="out", verbose=FALSE))
xbrlDoAll(urls[1], cache.dir="NULL", prefix.out ="out", verbose=FALSE)
?xbrlDoAll
inst <- "https://www.sec.gov/Archives/edgar/data/21344/000002134413000050/ko-20130927.xml"
xbrlDoAll(inst, cache.dir="NULL", prefix.out ="out", verbose=FALSE)
library(curl)
library(XBRL)
library(data.table)
xbrlDoAll(urls[1], cache.dir="NULL", prefix.out ="out", verbose=FALSE)
file.remove("out_calculations.csv", "out_contexts.csv", "out_definitions.csv",
"out_elements.csv", "out_facts.csv", "out_footnotes.csv",
"out_labels.csv", "out_presentations.csv", "out_roles.csv", "out_units.csv")
unlink("XBRLcache", recursive = TRUE)
description <- NULL
roleId <- NULL
labelRole <- NULL
labelString <- NULL
unitId <- NULL
fact <- NULL
contextId <- NULL
startDate <- NULL
endDate <- NULL
GetInstFile <- function(url) {
XBRL::xbrlDoAll(url, cache.dir=NULL, prefix.out ="out", verbose=FALSE)
}
xbrlDoAll(urls[1], cache.dir="NULL", prefix.out ="out", verbose=FALSE)
options(stringsAsFactors = FALSE)
test <- xbrlDoAll(urls[1], cache.dir="NULL", prefix.out ="out", verbose=FALSE)
GetInstFile <- function(url) {
XBRL::xbrlDoAll(url, cache.dir='xbrl.cache', prefix.out ="out", verbose=FALSE)
}
GetInstFile('urls[1]')
urls
urls[1]
GetInstFile(urls[1])
inst <- "https://www.sec.gov/Archives/edgar/data/21344/000002134413000050/ko-20130927.xml"
xbrl.vars <- xbrlDoAll(inst, cache.dir="XBRLcache", prefix.out="out", verbose=TRUE)
sessionInfo()
devtools::install_github("jsta/XBLR")
update.packages()
ticker <- 'fb'
GetInstFile <- function(url) {
XBRL::xbrlDoAll(url, cache.dir=NULL, prefix.out ="out", verbose=FALSE)
}
urls
edgarFiles <- fread('data/tempEdgar.csv')
library(tidyquant)
library(lubridate)
library(DT)
library(data.table)
library(scales)
library(finreportr)
library(XBRL)
library(RCurl)
ticker <- 'fb'
edgarFiles <- fread('data/tempEdgar.csv')
description <- NULL
roleId <- NULL
labelRole <- NULL
labelString <- NULL
unitId <- NULL
fact <- NULL
contextId <- NULL
startDate <- NULL
endDate <- NULL
GetInstFile <- function(url) {
XBRL::xbrlDoAll(url, cache.dir='xbrl.cache', prefix.out ="out", verbose=FALSE)
}
GetInstFile <- function(url) {
XBRL::xbrlDoAll(url, cache.dir= NULL, prefix.out ="out", verbose=FALSE)
}
GetInstFile(urls[1])
library(RCurl)
GetInstFile(urls[1])
GetInstFile <- function(url) {
XBRL::xbrlDoAll(url, cache.dir= NULL, prefix.out ="out", verbose=FALSE)
}
getOption("download.file.method")
getOption("download.file.method")
options(download.file.method = 'curl')
getOption("download.file.method")
options(download.file.method = 'curl')
GetInstFile(urls[1])
GetInstFile <- function(url) {
XBRL::xbrlDoAll(url, cache.dir= NULL, prefix.out ="out", verbose=FALSE)
}
options(download.file.method = 'curl')
GetInstFile(urls[1])
library(curl)
GetInstFile <- function(url) {
XBRL::xbrlDoAll(url, cache.dir=NULL, prefix.out ="out", verbose=FALSE)
}
GetInstFile <- function(url) {
XBRL::xbrlDoAll(url, cache.dir= NULL, prefix.out ="out", verbose=FALSE)
}
options(download.file.method = 'curl')
GetInstFile(urls[1])
GetInstFile <- function(url) {
XBRL::xbrlDoAll(url, cache.dir= NULL, prefix.out ="out", verbose=FALSE)
}
options(download.file.method = 'auto')
GetInstFile(urls[1])
options(download.file.method = 'wget')
GetInstFile(urls[1])
library(data.table)
library(XBRL)
library(curl)
description <- NULL
roleId <- NULL
labelRole <- NULL
labelString <- NULL
unitId <- NULL
fact <- NULL
contextId <- NULL
startDate <- NULL
endDate <- NULL
options(stringsAsFactors = FALSE,download.file.method = 'curl')
inst <- "http://edgar.sec.gov/Archives/edgar/data/21344/000002134414000008/ko-20131231.xml"
options(stringsAsFactors = FALSE,download.file.method = 'curl')
xbrl.vars <- xbrlDoAll(inst, cache.dir = "XBRLcache", prefix.out = 'out')
GetInstFile <- function(url) {
xbrlDoAll(url, cache.dir= 'xbrl.cache', prefix.out ="out", verbose=FALSE)
}
GetInstFile(url = 'https://www.sec.gov/Archives/edgar/data/1326801/000132680115000006/fb-20141231.xml')
description <- NULL
roleId <- NULL
labelRole <- NULL
labelString <- NULL
unitId <- NULL
fact <- NULL
contextId <- NULL
startDate <- NULL
endDate <- NULL
GetInstFile <- function(url) {
xbrlDoAll(url, cache.dir= 'xbrl.cache', prefix.out ="out", verbose=FALSE)
}
options(stringsAsFactors = FALSE,download.file.method = 'curl')
this <- GetInstFile(url = 'https://www.sec.gov/Archives/edgar/data/1326801/000132680115000006/fb-20141231.xml')
library(XBRL)
library(data.table)
library(XBRL)
library(curl)
GetInstFile <- function(url) {
xbrlDoAll(url, cache.dir= 'xbrl.cache', prefix.out ="out", verbose=FALSE)
}
options(stringsAsFactors = FALSE,download.file.method = 'curl')
this <- GetInstFile(url = 'https://www.sec.gov/Archives/edgar/data/1326801/000132680115000006/fb-20141231.xml')
this
this$unit
this$element
str(this, max.level = 1)
xbrl.vars <- this
xbrl.vars$fact %>%
filter(elementId == "us-gaap_SalesRevenueGoodsNet") %>%
left_join(xbrl.vars$context, by = "contextId") %>%
filter(is.na(dimension1)) %>%
select(startDate, endDate, fact, unitId, elementId) %>%
(knitr::kable)(format = "markdown")
library(dplyr)
xbrl.vars$fact %>%
filter(elementId == "us-gaap_SalesRevenueGoodsNet") %>%
left_join(xbrl.vars$context, by = "contextId") %>%
filter(is.na(dimension1)) %>%
select(startDate, endDate, fact, unitId, elementId) %>%
(knitr::kable)(format = "markdown")
htmlTable::htmlTable(data.frame(Statements=
with(
xbrl.vars$role[xbrl.vars$role$type=="Statement", ],
paste(roleId, "\n<br/>", definition, "\n<p/>")
)),
align = "l",
rnames = FALSE
)
xbrl.vars$role[xbrl.vars$role$type=="Statement", ],
xbrl.vars$role[xbrl.vars$role$type=="Statement", ]
pres_df_num <-
pres_df %>%
left_join(xbrl.vars$fact, by = "elementId") %>%
left_join(xbrl.vars$context, by = "contextId") %>%
filter(is.na(dimension1)) %>%
filter(!is.na(endDate)) %>%
select(elOrder, contains("level"), elementId, fact, decimals, endDate) %>%
mutate( fact = as.numeric(fact) * 10^as.numeric(decimals)) %>%
spread(endDate, fact ) %>%
arrange(elOrder)
library(pander)
pres_df_num %>%
select(elementId, contains("2013"), contains("2012")) %>%
pandoc.table(
style = "rmarkdown",
split.table = 200,
justify = c("left", "right", "right")
)
GetInstFile <- function(url) {
XBRL::xbrlDoAll(url, cache.dir=NULL, prefix.out ="out", verbose=FALSE)
}
instFile <- GetInstFile(inst.url)
rm(list=ls())
